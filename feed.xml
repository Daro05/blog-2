<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://prrao87.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://prrao87.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-08-09T17:42:48-05:00</updated><id>https://prrao87.github.io/blog/feed.xml</id><title type="html">Inverse Entropy</title><subtitle>A place for data science, machine learning, NLP and other interesting computing topics.</subtitle><entry><title type="html">Blogging for Data Scientists: Moving Away from Medium</title><link href="https://prrao87.github.io/blog/blogging-for-data-scientists/" rel="alternate" type="text/html" title="Blogging for Data Scientists: Moving Away from Medium" /><published>2020-05-03T00:00:00-05:00</published><updated>2020-05-03T00:00:00-05:00</updated><id>https://prrao87.github.io/blog/blogging-for-data-scientists</id><content type="html" xml:base="https://prrao87.github.io/blog/blogging-for-data-scientists/">&lt;p&gt;&lt;img src=&quot;../images/posts/laptop.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I recently began using &lt;a href=&quot;https://github.com/fastai/fastpages&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt;&lt;/a&gt;, a blogging platform based on GitHub Pages and Jekyll, that makes it easier to write technical blog posts using Jupyter notebooks. Over the years, I‚Äôd become accustomed to the familiarity and simplicity of Medium‚Äôs interface. Although migrating to a custom static blog site is quite intimidating for someone like me who‚Äôs never done it before, I decided to go ahead with it anyway. I also began thinking about what it is that makes me blog in the first place. And the more I thought about it, the more I realized Medium wasn‚Äôt the right platform for me any more. If you‚Äôre a Data Scientist, or anyone in computing who likes writing blog posts with code snippets and discussing workflows, seriously, please, reconsider using Medium as your default option.&lt;/p&gt;

&lt;h2 id=&quot;whats-wrong-with-medium&quot;&gt;What‚Äôs wrong with Medium?&lt;/h2&gt;
&lt;p&gt;Okay, so you already have a Medium account, are comfortable with its interface, and have been happily publishing posts for months without any problems. But just take a step back for a moment and think about it, and you‚Äôll see there are a number of problems.&lt;/p&gt;

&lt;h3 id=&quot;free-isnt-free&quot;&gt;Free isn‚Äôt free&lt;/h3&gt;
&lt;p&gt;As a data scientist and otherwise computer-savvy person, you‚Äôll have spent countless hours on stackoverflow and other blogs, all of which provided you that knowledge for &lt;em&gt;free&lt;/em&gt;. No strings attached (alright, some of them did come with ads, I‚Äôll admit). On the other hand, Medium‚Äôs exasperating drive to promote starred posts that are behind a paywall has proven its goals are the exact opposite. Your posts will be pushed to the top of Medium‚Äôs recommendation list if it has the most click-baity, contrarian title, commonly used tech jargon, and of course, the famous üüä icon. If most Data Science and computing-related posts on Medium were written by people who acquired their knowledge (largely) through free portals, why should Medium be a gatekeeper to spreading more knowledge in this space?&lt;/p&gt;

&lt;p&gt;Note, I say this &lt;em&gt;having been a paid subscriber&lt;/em&gt; to Medium for more than two years. As time went on, I found myself getting less and less value from my subscription. Yes, I‚Äôm aware that one can view paywalled Medium articles for free in incognito mode, but the sheer inconvenience of having to bypass a paywall each time I need to take a quick glance at possibly useful information is a huge disincentive on its own. Not to mention the annoyance of having to see that ‚Äúsubscribe to Medium‚Äù message every time I open a post (I know, because I‚Äôve been there, done that and and &lt;strong&gt;still&lt;/strong&gt; not changed the world)!&lt;/p&gt;

&lt;h3 id=&quot;poor-user-experience-with-code-formatting&quot;&gt;Poor user experience with code-formatting&lt;/h3&gt;
&lt;p&gt;Because Medium wasn‚Äôt written from the ground up to support code-strewn blog posts (including inline code-formatting was a &lt;a href=&quot;https://medium.engineering/inline-code-cc32ff2d463&quot;&gt;mere afterthought&lt;/a&gt;) - this leads to a lot of Medium posts being written with just bland code snippets, without syntax-highlighting. A significant burden is placed on the writer to convert individual blocks of &lt;a href=&quot;https://sigdelsanjog.com.np/github-share-github-gists-on-medium/&quot;&gt;code to GitHub gists&lt;/a&gt; and embedded into a Medium post for a decent-looking code snippet that can be read and understood easily. Most writers choose not to use gists due to the inconvenience factor (or are simply unaware of how to use them), instead publishing code snippets using Medium‚Äôs inbuilt code formatter without syntax-highlighting - this makes for a poor user experience from the reader‚Äôs &lt;em&gt;and&lt;/em&gt; writer‚Äôs perspective.&lt;/p&gt;

&lt;h3 id=&quot;non-existent-support-for-mathematical-symbols&quot;&gt;Non-existent support for mathematical symbols&lt;/h3&gt;
&lt;p&gt;You‚Äôre limited to posting ugly images of mathematical symbols and equations on Medium. While this may look okay at the time of writing your post, it‚Äôs almost guaranteed to compromise quality when viewed on a host of different devices (try loading a math-heavy Medium post on a device with dark-mode enabled). Quality aside, it‚Äôs generally considered poor practice to post mathematical symbols as images (&lt;a href=&quot;https://www.washington.edu/doit/how-do-i-create-online-math-content-accessible-students-who-are-blind&quot;&gt;for accessibility reasons&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&quot;reliance-on-a-single-platform-for-content&quot;&gt;Reliance on a single platform for content&lt;/h3&gt;
&lt;p&gt;As Medium‚Äôs user base has grown, more and more people are writing content for its top publications (in Data Science and machine learning), which is not in itself a bad thing. However,  encouraging users to subscribe to a publication and providing a ‚Äúone-stop-shop‚Äù for all things Data Science/ML-related means that users are pigeon-holed into obtaining their information from a single website. In the long run, great information is self-selected by a decentralized system (such as Google‚Äôs search algorithm), so it‚Äôs highly likely that your post will show up at the top of a relevant Google search anyway.&lt;/p&gt;

&lt;h2 id=&quot;what-does-fastpages-offer&quot;&gt;What does &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; offer?&lt;/h2&gt;
&lt;p&gt;For those of you who are intimidated by the thought of building your own blog site from scratch, &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; (&lt;a href=&quot;https://fastpages.fast.ai/fastpages/jupyter/2020/02/21/introducing-fastpages.html&quot;&gt;built by Jeremy Howard and Hamel Husain&lt;/a&gt;) lets you do all of this from within the comfort of GitHub. Because it‚Äôs based on &lt;a href=&quot;https://pages.github.com/&quot;&gt;GitHub Pages&lt;/a&gt; - a free service for building and hosting custom websites - it doesn‚Äôt come with any hidden baggage. All you need is a GitHub account, which you‚Äôll already have, or are considering getting if you‚Äôre coding on a regular basis.&lt;/p&gt;

&lt;p&gt;Jeremy provides a summary in his Tweet thread (with the linked blog post inside):&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;We&amp;#39;re launching `fastpages`, a platform which allows you to host a blog for free, with no ads. You can blog with &lt;a href=&quot;https://twitter.com/ProjectJupyter?ref_src=twsrc%5Etfw&quot;&gt;@ProjectJupyter&lt;/a&gt; notebooks, &lt;a href=&quot;https://twitter.com/Office?ref_src=twsrc%5Etfw&quot;&gt;@office&lt;/a&gt; Word, directly from &lt;a href=&quot;https://twitter.com/github?ref_src=twsrc%5Etfw&quot;&gt;@github&lt;/a&gt;&amp;#39;s markdown editor, etc.&lt;br /&gt;&lt;br /&gt;Nothing to install, &amp;amp; setup is automated!&lt;a href=&quot;https://t.co/dNSA0oQUrN&quot;&gt;https://t.co/dNSA0oQUrN&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jeremy #Masks4All Howard (@jeremyphoward) &lt;a href=&quot;https://twitter.com/jeremyphoward/status/1232059428238581760?ref_src=twsrc%5Etfw&quot;&gt;February 24, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;But in addition to ad-free hosting, here are a few fundamental reasons why it makes sense to consider using your own blog site.&lt;/p&gt;

&lt;h3 id=&quot;pre-built-user-interface&quot;&gt;Pre-built user interface&lt;/h3&gt;
&lt;p&gt;A large part of the hassle of building your own blog is designing and implementing a decent-looking UI. With &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt;, all the initial heavy lifting is done for you - a more than decent UI is provided by default, which contains all the essential components that one might ask for in a personal blog site:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ability to use a personal domain name (&lt;code class=&quot;highlighter-rouge&quot;&gt;myname.dev&lt;/code&gt;) instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;myname.github.io/blogname&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Cleanly organized posts with image previews&lt;/li&gt;
  &lt;li&gt;An ‚ÄúAbout‚Äù section describing who you are and your background&lt;/li&gt;
  &lt;li&gt;Tags for searching blog posts by topic&lt;/li&gt;
  &lt;li&gt;Badges that link visitors to your GitHub/Twitter pages&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ready-made-code-formatting-and-syntax-highlighting&quot;&gt;Ready-made code formatting and syntax-highlighting&lt;/h3&gt;
&lt;p&gt;Posts in &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; are written directly in a Jupyter notebook, or in Markdown using a feature-rich editor (like &lt;a href=&quot;https://code.visualstudio.com/docs/languages/markdown&quot;&gt;VS Code&lt;/a&gt;). Depending on the language you‚Äôre highlighting, it‚Äôs a walk in the park to include code snippets that look exactly as you intended them to.&lt;/p&gt;

&lt;h3 id=&quot;support-for-latex-style-equations&quot;&gt;Support for LaTeX-style equations&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; goes the extra mile and allows you to type in LaTeX-style mathematical symbols and equations, rendering them on your blog for you. This works with inline as well as stand-alone equations.&lt;/p&gt;

&lt;p&gt;Example inline equation: $\alpha + \beta = \gamma$&lt;/p&gt;

&lt;h3 id=&quot;keep-code-and-the-related-blog-explaining-it-all-in-one-place&quot;&gt;Keep code and the related blog explaining it all in one place&lt;/h3&gt;
&lt;p&gt;Because Jupyter notebooks are essentially self-documenting blog posts themselves, &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; turbo-charges their use by offering custom syntax hints to directly publish a Jupyter notebook as a blog post (using an extension of the &lt;a href=&quot;https://github.com/fastai/nbdev&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nbdev&lt;/code&gt;&lt;/a&gt; project). This is extremely useful, because it essentially reduces the labour of describing your Data Science workflow and experiments by allowing you to document your thought process &lt;em&gt;along with the code&lt;/em&gt; itself. This is a radical shift from the way you‚Äôll have been conventionally blogging about such workflows (e.g. via Medium), where you‚Äôll have had multiple browser tabs open for copy-pasting code, GitHub gists and more.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: Additional thoughts from my own experience blogging with notebooks&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Personally, this is one aspect of using &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; that has changed the way I think about blogging. Earlier, writing a blog post was always a significant upfront planning effort on my part - I‚Äôd lay out snippets of code that I‚Äôd need to publish in the blog beforehand. Then, I‚Äôd painstakingly create GitHub gists for each snippet so that I could embed them (with full syntax-highlighting) into my Medium post in between parts of the workflow where I was trying to explain a point. With notebooks, the whole process is organic, because you‚Äôre testing code snippets on the fly &lt;em&gt;along with the text for your blog&lt;/em&gt; side-by-side!&lt;/p&gt;

&lt;p&gt;Even when using pure Markdown to write a blog post (as I did with this one), it‚Äôs as simple as working in a text editor and using &lt;code class=&quot;highlighter-rouge&quot;&gt;nbdev&lt;/code&gt; syntax to render effects such as highlighted notes and code folding (as shown in the &lt;a href=&quot;https://fastpages.fast.ai/fastpages/jupyter/2020/02/21/introducing-fastpages.html&quot;&gt;original blog post&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&quot;some-faqs-on-using-fastpages&quot;&gt;Some FAQs on using &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt;&lt;/h2&gt;

&lt;h4 id=&quot;what-about-viewership-wont-i-get-significantly-fewer-readers&quot;&gt;What about viewership? Won‚Äôt I get significantly fewer readers?&lt;/h4&gt;
&lt;p&gt;It‚Äôs important to remember that viewership is just a vanity metric when it comes to personal blogs. It really doesn‚Äôt matter how many people see your posts on a weekly basis - what matters more is the value you derived by taking the time to write the post in the first place (by applying existing skills and learning new ones). A few readers might take the effort to react or post comments, but almost all are ‚Äúsilent‚Äù visitors - this is true regardless of the blogging platform used, so just focus on your own learning and writing skills!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: Having been writing articles on Medium for almost two years, I‚Äôve noted that Google searches and external referrals are the biggest contributors to new viewers in the long term. Content that is insightful and well-written should inevitably be found via the relevant keyword searches over time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;wont-my-productivity-be-affected-if-i-have-to-make-commits-on-github-each-time&quot;&gt;Won‚Äôt my productivity be affected if I have to make commits on GitHub each time?&lt;/h4&gt;
&lt;p&gt;If you‚Äôre writing blog posts involving code snippets, it‚Äôs very likely you‚Äôre already committing the code &lt;em&gt;somewhere&lt;/em&gt;. Also, if you‚Äôre just starting off in the field and are looking to increase your credibility by publishing insightful, well-crafted software development workflows, hosting your blog on GitHub can only bring in more brownie points (by improving your active commit history).&lt;/p&gt;

&lt;h4 id=&quot;can-i-work-on-drafts-of-my-post-before-actually-publishing-it&quot;&gt;Can I work on drafts of my post before actually publishing it?&lt;/h4&gt;
&lt;p&gt;A simple way to do this is to create a new folder &lt;code class=&quot;highlighter-rouge&quot;&gt;ideas&lt;/code&gt; and simply write your posts in notebooks/Markdown files while committing to this directory. Only posts that are in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_notebooks&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;_word&lt;/code&gt; directories are published; all posts in other directories are ignored (but are still backed up on GitHub). Another alternative is to use the Front Matter option &lt;code class=&quot;highlighter-rouge&quot;&gt;hide: true&lt;/code&gt; so that Jekyll doesn‚Äôt render the post on the web page (see the full description of Front Matter &lt;a href=&quot;https://github.com/fastai/fastpages#customizing-blog-posts-with-front-matter&quot;&gt;in the &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; documentation&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;

&lt;h3 id=&quot;why-do-you-write-blog-posts-in-the-first-place&quot;&gt;Why do you write blog posts in the first place?&lt;/h3&gt;

&lt;p&gt;I‚Äôve learned firsthand that writing about complex technical workflows cements those concepts in my brain. The more you do it, the better you become at conceptualizing those workflows for new, unseen situations. Using a service like Medium offers you &lt;em&gt;the wrong reward function&lt;/em&gt;, such as receiving appreciation through claps. It also creates the delusion that having more views (or claps) on your post matters in any tangible way. Real jobs in the real world come from networking and talking to the right people, and a large part of that is how you &lt;em&gt;communicate&lt;/em&gt; your thought process and showcase your portfolio and skills online. What better way to do this than getting your ideas out there using your own blog site, with its own quirks and colour schemes, and most importantly, &lt;em&gt;without&lt;/em&gt; the pressure of expecting virtual ‚Äúpats on the back‚Äù from an online system!&lt;/p&gt;

&lt;p&gt;The goal of writing a technical blog post, in my view, should be to provide at least &lt;em&gt;some useful insight&lt;/em&gt; to the reader. Even if your post just benefits five people in the entire world, that‚Äôs a worthy reward in itself - because it contains knowledge that was likely gained through a free and open portal (such as someone else‚Äôs blog), and is shared with someone else through another free portal (this also aligns well with the &lt;a href=&quot;https://webfoundation.org/about/vision/history-of-the-web/&quot;&gt;overall goals of the world wide web&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&quot;where-to-from-here&quot;&gt;Where to from here?&lt;/h3&gt;
&lt;p&gt;While &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; is a great introduction to deploying and maintaining your own custom site, in the long run, you‚Äôre not tied to hosting your site on GitHub and the &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; platform. You‚Äôre allowed to save the intermediate Markdown files generated for each of your posts, so you can always migrate your blogs to another service if you need to.&lt;/p&gt;

&lt;p&gt;If you‚Äôre a Data Scientist, the great thing about using a tool like fastpages is that there‚Äôs already a &lt;a href=&quot;https://forums.fast.ai/t/fastpages-github-pages-blog-using-nbdev/62828&quot;&gt;community forum&lt;/a&gt; with questions on commonly faced problems and great answers on functionality. It‚Äôs never too late to start working on your own blog, so keep writing and happy blogging!&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;appendix-examples-on-customizing-fastpages&quot;&gt;Appendix: Examples on customizing &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Even if you don‚Äôt know all that much about CSS or SCSS (I don‚Äôt either), it‚Äôs not that hard to customize some of the page‚Äôs aesthetics.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: SCSS (‚ÄòSass‚Äô CSS) is basically CSS with rule-nesting, loops and other logic added on top. &lt;a href=&quot;https://dev.to/rishiabee/awesome-scss-the-basics-dh8&quot;&gt;Here‚Äôs a simple tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;change-syntax-highlight-colours&quot;&gt;Change syntax-highlight colours&lt;/h3&gt;
&lt;p&gt;The default version of fastpages comes with dark syntax-highlighting for code, based on the popular Dracula theme. If you don‚Äôt particularly like all the colours in this theme, it‚Äôs relatively straightforward to customize via CSS.&lt;/p&gt;

&lt;p&gt;In the &lt;code class=&quot;highlighter-rouge&quot;&gt;_sass/minima&lt;/code&gt; directory , copy the existing file &lt;code class=&quot;highlighter-rouge&quot;&gt;minima/custom-styles.scss/fastpages-dracula-highlight.scss&lt;/code&gt; (containing the Dracula colour scheme) to a new file &lt;code class=&quot;highlighter-rouge&quot;&gt;custom-code-colors.scss&lt;/code&gt; in the same directory. Point to this new file in &lt;code class=&quot;highlighter-rouge&quot;&gt;minima/custom-styles.scss&lt;/code&gt; as follows.&lt;/p&gt;

&lt;div class=&quot;language-css highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;/* @import &quot;minima/fastpages-dracula-highlight&quot;; */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;@import&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&quot;minima/custom-code-colors&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To change the colour definitions at the top, replace the relevant Hex code for the &lt;code class=&quot;highlighter-rouge&quot;&gt;$dt-purple&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;$dt-pink&lt;/code&gt; colours with new colour shades (VS Code has a really nice &lt;a href=&quot;https://mspoweruser.com/visual-studio-code-now-really-useful-color-picker-built/&quot;&gt;colour picker built-in&lt;/a&gt;). In my case, I chose a lighter purple definition. Next, I changed the keyword colour scheme under the &lt;code class=&quot;highlighter-rouge&quot;&gt;.highlight&lt;/code&gt; selector.&lt;/p&gt;

&lt;div class=&quot;language-css highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;dt-purple&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;#c792ea&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;nc&quot;&gt;.highlight&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;.k,&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;.o,&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;.cp,&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;.kc,&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;.kn,&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;.kp,&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;.kr,&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;.nt,&lt;/span&gt;
    &lt;span class=&quot;err&quot;&gt;.ow&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nl&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dt-purple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Other properties of the selector can be customized with new colours the same way.&lt;/p&gt;

&lt;h3 id=&quot;change-the-font-and-default-font-size&quot;&gt;Change the font and default font-size&lt;/h3&gt;
&lt;p&gt;If you want to tweak the fonts and font sizes used by &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt;, this can be done as follows.&lt;/p&gt;

&lt;h4 id=&quot;code-font&quot;&gt;Code font&lt;/h4&gt;
&lt;p&gt;I noticed that on my Linux machine, the code fonts that were being requested were not actually available - this was rendering code in the live blog using sans-serif fonts, which in my opinion looks rather ugly. I changed it to a monospace font (DejaVu Sans Mono) using the same &lt;code class=&quot;highlighter-rouge&quot;&gt;minima/custom-styles.scss&lt;/code&gt; created in the previous example:&lt;/p&gt;

&lt;div class=&quot;language-css highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;.input_area&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;pre&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;.input_area&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;div&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;margin-bottom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2rem&lt;/span&gt; &lt;span class=&quot;cp&quot;&gt;!important&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;margin-top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1.5rem&lt;/span&gt; &lt;span class=&quot;cp&quot;&gt;!important&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;padding-bottom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;cp&quot;&gt;!important&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;padding-top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;cp&quot;&gt;!important&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;background&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;#323443&lt;/span&gt; &lt;span class=&quot;cp&quot;&gt;!important&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;-webkit-font-smoothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;antialiased&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;text-rendering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizeLegibility&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;font-family&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DejaVu&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sans&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mono&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;monospace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;border-radius&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;font-size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;main-blog-font&quot;&gt;Main blog font&lt;/h4&gt;
&lt;p&gt;To change the content font size globally for all blog posts, edit the &lt;code class=&quot;highlighter-rouge&quot;&gt;minima/fastpages-styles.scss&lt;/code&gt; file. Styles for non-headings are modified using the &lt;code class=&quot;highlighter-rouge&quot;&gt;post-content&lt;/code&gt; selector:
`&lt;/p&gt;
&lt;div class=&quot;language-css highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;/* make non-headings slightly lighter */&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;.post-content&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;.post-content&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;li&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;nl&quot;&gt;font-size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;18px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;nl&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;#515151&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;adding-the-disqus-comment-system&quot;&gt;Adding the &lt;em&gt;Disqus&lt;/em&gt; comment system&lt;/h3&gt;
&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;fastpages&lt;/code&gt; documentation recommends using the &lt;em&gt;utteranc.es&lt;/em&gt; service within GitHub for ad-free, non-trackable comments. While this is a great, light-weight option to allow users to comment on your post, it does require users to sign up for a GitHub account in order to comment.&lt;/p&gt;

&lt;p&gt;An alternate option is to use &lt;em&gt;Disqus&lt;/em&gt;, which allows users to sign in using their social Media accounts and post comments instead. However, Disqus isn‚Äôt ad-free, and does involve some anonymous tracking, so it‚Äôs worth considering this before going ahead and enabling it for your site.&lt;/p&gt;

&lt;p&gt;In my case, I wanted to allow comments from users who may not be comfortable signing up for a GitHub account just for this purpose, so I went ahead and enabled Disqus comments using the instructions &lt;a href=&quot;https://desiredpersona.com/disqus-comments-jekyll/&quot;&gt;shown here&lt;/a&gt;.&lt;/p&gt;</content><author><name>Prashanth Rao</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://prrao87.github.io/blog/images/posts/laptop.jpeg" /><media:content medium="image" url="https://prrao87.github.io/blog/images/posts/laptop.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Turbo-charge your spaCy NLP pipeline</title><link href="https://prrao87.github.io/blog/spacy/nlp/performance/2020/05/02/spacy-multiprocess.html" rel="alternate" type="text/html" title="Turbo-charge your spaCy NLP pipeline" /><published>2020-05-02T00:00:00-05:00</published><updated>2020-05-02T00:00:00-05:00</updated><id>https://prrao87.github.io/blog/spacy/nlp/performance/2020/05/02/spacy-multiprocess</id><content type="html" xml:base="https://prrao87.github.io/blog/spacy/nlp/performance/2020/05/02/spacy-multiprocess.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-05-02-spacy-multiprocess.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/blog/images/copied_from_nb/../images/rocket.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Background&quot;&gt;Background&lt;a class=&quot;anchor-link&quot; href=&quot;#Background&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Consider you have a large text dataset on which you want to apply some non-trivial NLP transformations, such as stopword removal followed by lemmatizing the words  (i.e. reducing them to root form) in the text. &lt;a href=&quot;https://spacy.io/usage&quot;&gt;spaCy&lt;/a&gt; is an industrial strength NLP library designed for just such a task.&lt;/p&gt;
&lt;p&gt;In the example shown below, the &lt;a href=&quot;https://www.kaggle.com/nzalake52/new-york-times-articles&quot;&gt;New York Times dataset&lt;/a&gt; is used to showcase how to significantly speed up a spaCy NLP pipeline. The goal is to take in an article's text, and speedily return a list of lemmas with unnecessary words, i.e. &lt;em&gt;stopwords&lt;/em&gt;, removed.&lt;/p&gt;
&lt;p&gt;Pandas DataFrames provide a convenient interface to work with tabular data of this nature. First, import the necessary modules shown.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;spacy&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Initial-steps&quot;&gt;Initial steps&lt;a class=&quot;anchor-link&quot; href=&quot;#Initial-steps&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The news data is obtained by running the &lt;a href=&quot;https://github.com/prrao87/blog/tree/master/_notebooks/data/spacy_multiprocess&quot;&gt;preprocessing notebook&lt;/a&gt; (&lt;code&gt;./data/preprocessing.ipynb&lt;/code&gt;), which processes the raw text file downloaded from Kaggle and performs some basic cleaning on it. This step generates a file that contains the tabular data (stored as &lt;code&gt;nytimes.tsv&lt;/code&gt;). A curated stopword file is also provided in &lt;a href=&quot;https://github.com/prrao87/blog/tree/master/_notebooks/data/spacy_multiprocess&quot;&gt;the same directory&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Additionally, during initial testing, we can limit the size of the DataFrame being worked on (to a subset of the total number of articles) for faster execution. For the final run, disable the limit by setting it to zero.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;inputfile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;data/spacy_multiprocess/nytimes-sample.tsv&amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stopwordfile&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;data/spacy_multiprocess/stopwords/stopwords.txt&amp;quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Load-spaCy-model&quot;&gt;Load spaCy model&lt;a class=&quot;anchor-link&quot; href=&quot;#Load-spaCy-model&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Since we will not be doing any specialized tasks such as dependency parsing and named entity recognition in this exercise, these components are disabled when loading the spaCy model.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;div class=&quot;flash flash-success&quot;&gt;
    &lt;svg class=&quot;octicon octicon-checklist&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M16 8.5l-6 6-3-3L8.5 10l1.5 1.5L14.5 7 16 8.5zM5.7 12.2l.8.8H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h7c.55 0 1 .45 1 1v6.5l-.8-.8c-.39-.39-1.03-.39-1.42 0L5.7 10.8a.996.996 0 000 1.41v-.01zM4 4h5V3H4v1zm0 2h5V5H4v1zm0 2h3V7H4v1zM3 9H2v1h1V9zm0-2H2v1h1V7zm0-2H2v1h1V5zm0-2H2v1h1V3z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Tip: &lt;/strong&gt;spaCy has a &lt;code&gt;sentencizer&lt;/code&gt; component that can be plugged into a blank pipeline.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The sentencizer pipeline simply performs tokenization and sentence boundary detection, following which lemmas can be extracted as token properties.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spacy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;en_core_web_sm&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;tagger&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;parser&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;ner&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;sentencizer&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;A method is defined to read in stopwords from a text file and convert it to a set in Python (for efficient lookup).&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_stopwords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Return a set of stopwords read in from a file.&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stopwordfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;stopwords&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;stopwords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Convert to set for performance&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;stopwords_set&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stopwords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stopwords_set&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;stopwords&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_stopwords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Read-in-New-York-Times-Dataset&quot;&gt;Read in New York Times Dataset&lt;a class=&quot;anchor-link&quot; href=&quot;#Read-in-New-York-Times-Dataset&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The pre-processed version of the NYT news dataset is read in as a Pandas DataFrame. The columns are named &lt;code&gt;date&lt;/code&gt;, &lt;code&gt;headline&lt;/code&gt; and &lt;code&gt;content&lt;/code&gt; - the text present in the content column is what will be preprocessed to remove stopwords and generate token lemmas.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;read_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Read in a tab-separated file with date, headline and news content&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;headline&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_datetime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;%Y-%m-&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;date&lt;/th&gt;
      &lt;th&gt;headline&lt;/th&gt;
      &lt;th&gt;content&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;washington nationals max scherzer baffles mets...&lt;/td&gt;
      &lt;td&gt;Stellar pitching kept the Mets afloat in the f...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;mayor de blasios counsel to leave next month t...&lt;/td&gt;
      &lt;td&gt;Mayor Bill de Blasio‚Äôs counsel and chief legal...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;three men charged in killing of cuomo administ...&lt;/td&gt;
      &lt;td&gt;In the early morning hours of Labor Day last y...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Define-text-cleaner&quot;&gt;Define text cleaner&lt;a class=&quot;anchor-link&quot; href=&quot;#Define-text-cleaner&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Since the news article data comes from a raw HTML dump, it is very messy and contains a host of unnecessary symbols, social media handles, URLs and other artifacts. An easy way to clean it up is to use a regex that parses only alphanumeric strings and hyphens (so as to include hyphenated words) that are between a given length (3 and 50). This filters each document down to only meaningful text for the lemmatizer.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cleaner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Extract relevant text from DataFrame using a regex&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Regex pattern for only alphanumeric, hyphenated text with 3 or more chars&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;[A-Za-z0-9\-]{3,50}&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;clean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cleaner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;date&lt;/th&gt;
      &lt;th&gt;headline&lt;/th&gt;
      &lt;th&gt;content&lt;/th&gt;
      &lt;th&gt;clean&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;washington nationals max scherzer baffles mets...&lt;/td&gt;
      &lt;td&gt;Stellar pitching kept the Mets afloat in the f...&lt;/td&gt;
      &lt;td&gt;Stellar pitching kept the Mets afloat the firs...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;mayor de blasios counsel to leave next month t...&lt;/td&gt;
      &lt;td&gt;Mayor Bill de Blasio‚Äôs counsel and chief legal...&lt;/td&gt;
      &lt;td&gt;Mayor Bill Blasio counsel and chief legal advi...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;three men charged in killing of cuomo administ...&lt;/td&gt;
      &lt;td&gt;In the early morning hours of Labor Day last y...&lt;/td&gt;
      &lt;td&gt;the early morning hours Labor Day last year gr...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Now that we have just the clean, alphanumeric tokens left over, these can be further cleaned up by removing stopwords before proceeding to lemmatization.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Option-1:-Sequentially-process-DataFrame-column&quot;&gt;Option 1: Sequentially process DataFrame column&lt;a class=&quot;anchor-link&quot; href=&quot;#Option-1:-Sequentially-process-DataFrame-column&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The straightforward way to process this text is to use an existing method, in this case the &lt;code&gt;lemmatize&lt;/code&gt; method shown below, and apply it to the &lt;a href=&quot;/blog/images/copied_from_nb/clean&quot;&gt;&lt;code&gt;clean&lt;/code&gt;&lt;/a&gt; column of the DataFrame using &lt;code&gt;pandas.Series.apply&lt;/code&gt;. Lemmatization is done using the spaCy's underlying &lt;a href=&quot;https://spacy.io/usage/spacy-101#annotations&quot;&gt;&lt;code&gt;Doc&lt;/code&gt; representation&lt;/a&gt; of each token, which contains a &lt;code&gt;lemma_&lt;/code&gt; property. Stopwords are removed simultaneously with the lemmatization process, as each of these steps involves iterating through the same list of tokens.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lemmatize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sd&quot;&gt;&amp;quot;&amp;quot;&amp;quot;Perform lemmatization and stopword removal in the clean text&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;       Returns a list of lemmas&lt;/span&gt;
&lt;span class=&quot;sd&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lemma_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lemma_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;
                  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_alpha&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stopwords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lemma_list&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;The resulting lemmas are stored as a list in a separate column &lt;code&gt;preproc&lt;/code&gt; as shown below.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%%time&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;preproc&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;clean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lemmatize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;preproc&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;CPU times: user 48.5 s, sys: 146 ms, total: 48.6 s
Wall time: 48.6 s
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;date&lt;/th&gt;
      &lt;th&gt;content&lt;/th&gt;
      &lt;th&gt;preproc&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;Stellar pitching kept the Mets afloat in the f...&lt;/td&gt;
      &lt;td&gt;[stellar, pitch, keep, mets, afloat, half, sea...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;Mayor Bill de Blasio‚Äôs counsel and chief legal...&lt;/td&gt;
      &lt;td&gt;[mayor, bill, blasio, counsel, chief, legal, a...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;In the early morning hours of Labor Day last y...&lt;/td&gt;
      &lt;td&gt;[early, labor, group, gunman, street, gang, cr...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Applying this method to the &lt;a href=&quot;/blog/images/copied_from_nb/clean&quot;&gt;&lt;code&gt;clean&lt;/code&gt;&lt;/a&gt; column of the DataFrame and timing it shows that it takes almost a minute to run on 8,800 news articles.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Option-2:-Use-nlp.pipe&quot;&gt;Option 2: Use &lt;code&gt;nlp.pipe&lt;/code&gt;&lt;a class=&quot;anchor-link&quot; href=&quot;#Option-2:-Use-nlp.pipe&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Can we do better? in the &lt;a href=&quot;https://spacy.io/api/language#pipe&quot;&gt;spaCy documentation&lt;/a&gt;, it is stated that &quot;processing texts as a stream is usually more efficient than processing them one-by-one&quot;. This is done by calling a language pipe, which internally divides the data into batches to reduce the number of pure-Python function calls. This means that the larger the data, the better the performance gain that can be obtained by &lt;code&gt;nlp.pipe&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To use the language pipe to stream texts, a new lemmatizer method is defined that directly works on a spaCy &lt;code&gt;Doc&lt;/code&gt; object. This method is then called in batches to work on a &lt;em&gt;sequence&lt;/em&gt; of &lt;code&gt;Doc&lt;/code&gt; objects that are streamed through the pipe as shown below.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lemmatize_pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lemma_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lemma_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;
                  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_alpha&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stopwords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lemma_list&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;preprocess_pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;preproc_pipe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;preproc_pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lemmatize_pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preproc_pipe&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Just as before, a new column is created by passing data from the &lt;a href=&quot;/blog/images/copied_from_nb/clean&quot;&gt;&lt;code&gt;clean&lt;/code&gt;&lt;/a&gt; column of the existing DataFrame. Note that unlike in workflow #1 above, we do not use the &lt;code&gt;apply&lt;/code&gt; method here - instead, the column of data (an iterable) is directly passed as an argument to the preprocessor pipe method.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%%time&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;preproc_pipe&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprocess_pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;clean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;preproc_pipe&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;CPU times: user 51.6 s, sys: 144 ms, total: 51.8 s
Wall time: 51.8 s
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;date&lt;/th&gt;
      &lt;th&gt;content&lt;/th&gt;
      &lt;th&gt;preproc_pipe&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;Stellar pitching kept the Mets afloat in the f...&lt;/td&gt;
      &lt;td&gt;[stellar, pitch, keep, mets, afloat, half, sea...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;Mayor Bill de Blasio‚Äôs counsel and chief legal...&lt;/td&gt;
      &lt;td&gt;[mayor, bill, blasio, counsel, chief, legal, a...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;In the early morning hours of Labor Day last y...&lt;/td&gt;
      &lt;td&gt;[early, labor, group, gunman, street, gang, cr...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Timing this workflow doesn't seem to show improvement over the previous workflow, but as per the spaCy documentation, one would expect that as we work on bigger and bigger datasets, this approach should show some timing improvement (on average).&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Option-3:-Parallelize-the-work-using-joblib&quot;&gt;Option 3: Parallelize the work using joblib&lt;a class=&quot;anchor-link&quot; href=&quot;#Option-3:-Parallelize-the-work-using-joblib&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We can do still better! The previous workflows sequentially worked through each news document to produce the lemma lists, which were then appended to the DataFrame as a new column. Because each row's output is completely independent of the other, this is an &lt;em&gt;embarassingly parallel&lt;/em&gt; problem, making it ideal for using multiple cores.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;joblib&lt;/code&gt; library is recommended by spaCy for processing blocks of an NLP pipeline in parallel. Make sure that you &lt;code&gt;pip install joblib&lt;/code&gt; before running the below section.&lt;/p&gt;
&lt;p&gt;To parallelize the workflow, a few more helper methods must be defined.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Chunking:&lt;/strong&gt; The news article content is a list of (long) strings where each document represents a single article's text. This data must be fed in &quot;chunks&quot; to each worker process started by joblib. Each call of the &lt;code&gt;chunker&lt;/code&gt; method returns a generator that only contains that particular chunk's text as a list of strings. During lemmatization, each new chunk is retrieved based on the iterator index (with the previous chunks being &quot;forgotten&quot;).&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Flattening:&lt;/strong&gt; Once joblib creates a set of worker processes that work on each chunk, each worker returns a &quot;list of lists&quot; containing lemmas for each document. These lists are then combined by the executor to provide a 3-level nested final &quot;list of lists of lists&quot;. To ensure that the length of the output from the executor is the same as the actual number of articles, a &quot;flatten&quot; method is defined to combine the result into a list of lists containing lemmas. As an example, two parallel executors would return a final nested list of the form: &lt;code&gt;[[[a, b, c], [d, e, f]], [[g, h, i], [j, k, l]]]&lt;/code&gt;, where &lt;code&gt;[[a, b, c], [d, e, f]]&lt;/code&gt; and &lt;code&gt;[[g, h, i], [j, k, l]]&lt;/code&gt; refer to the output from each executor (the final output is then concatenated to a single list by joblib). A flattened version of this result would be &lt;code&gt;[[a, b, c], [d, e, f], [g, h, i], [j, k, l]]&lt;/code&gt;, i.e. with one level of nesting removed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to the above methods, a similar &lt;code&gt;nlp.pipe&lt;/code&gt; method is used as in workflow #2, on each chunk of texts. Each of these methods is wrapped into a &lt;code&gt;preprocess_parallel&lt;/code&gt; method that defines the number of worker processes to be used (7 in this case), breaks the input data into chunks and returns a flattened result that can then be appended to the DataFrame. For machine with a higher number of physical cores, the number of worker processes can be increased further.&lt;/p&gt;
&lt;p&gt;The parallelized workflow using joblib is shown below.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;joblib&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delayed&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;chunker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chunksize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chunksize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chunksize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_of_lists&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s2&quot;&gt;&amp;quot;Flatten a list of lists to a combined list&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sublist&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list_of_lists&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sublist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;process_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;preproc_pipe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nlp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;preproc_pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lemmatize_pipe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preproc_pipe&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;preprocess_parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chunksize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;multiprocessing&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;processes&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delayed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process_chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;do&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chunk&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chunker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chunksize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chunksize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%%time&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;preproc_parallel&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprocess_parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;clean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chunksize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;CPU times: user 683 ms, sys: 248 ms, total: 932 ms
Wall time: 17.2 s
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;preproc_parallel&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;date&lt;/th&gt;
      &lt;th&gt;content&lt;/th&gt;
      &lt;th&gt;preproc_parallel&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;Stellar pitching kept the Mets afloat in the f...&lt;/td&gt;
      &lt;td&gt;[stellar, pitch, keep, mets, afloat, half, sea...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;Mayor Bill de Blasio‚Äôs counsel and chief legal...&lt;/td&gt;
      &lt;td&gt;[mayor, bill, blasio, counsel, chief, legal, a...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;In the early morning hours of Labor Day last y...&lt;/td&gt;
      &lt;td&gt;[early, labor, group, gunman, street, gang, cr...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Timing this parallelized workflow shows significant performance gains (almost &lt;strong&gt;3x&lt;/strong&gt; reduction in run time)! As the number of documents becomes larger, the additional overhead of starting multiple worker threads with &lt;code&gt;joblib&lt;/code&gt; is quickly paid for, and this method can significantly outperform the sequential methods.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Effect-of-chunk-size-and-batch-size&quot;&gt;Effect of chunk size and batch size&lt;a class=&quot;anchor-link&quot; href=&quot;#Effect-of-chunk-size-and-batch-size&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Note that in the parallelized workflow, two parameters need to be specified - the optimum number can vary depending on the dataset. The &lt;code&gt;chunksize&lt;/code&gt; controls the size of each chunk being worked on by each process. In this example, for 8,800 documents, a chunksize of 1000 is used. Too small a chunksize would mean that a large number of worker threads would spawn to deal with the large number of chunks overall, which can slow down execution. Generally, a chunksize of several hundred documents to a few thousand is a good starting point (of course, this depends on how big each document in the data is so that the chunks can fit into memory).&lt;/p&gt;
&lt;p&gt;The batch size is parameter specific to &lt;code&gt;nlp.pipe&lt;/code&gt;, and again, a good value depends on the data being worked on. For reasonably long-sized text such as news articles, it makes sense to keep the batch size reasonably small (so that each batch doesn't contain &lt;em&gt;really&lt;/em&gt; long texts), so in this case 20 was chosen for the batch size. For other cases (e.g. Tweets) where each document is much shorter in length, a larger batch size can be used.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It is recommended to experiment with either parameter to see which combination produces the best performance&lt;/strong&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Sets-vs.-Lists&quot;&gt;Sets vs. Lists&lt;a class=&quot;anchor-link&quot; href=&quot;#Sets-vs.-Lists&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;div class=&quot;flash flash-warn&quot;&gt;
    &lt;svg class=&quot;octicon octicon-zap&quot; viewBox=&quot;0 0 10 16&quot; version=&quot;1.1&quot; width=&quot;10&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M10 7H6l3-7-9 9h4l-3 7 9-9z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Important: &lt;/strong&gt;Use sets over lists for lookups wherever possible.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Note that in the &lt;code&gt;get_stopwords()&lt;/code&gt; method defined earlier on, the list of stopwords read in from the stopword file was converted to a set before using it in the lemmatizer method for stopword removal via lookups. This is a very useful trick in general, but specifically for stopword removal, the use of sets becomes &lt;strong&gt;all the more important&lt;/strong&gt;. Why?&lt;/p&gt;
&lt;p&gt;In any realistic stopword list, such as this one for a news dataset, it's reasonable to expect &lt;em&gt;several hundred&lt;/em&gt; stopwords. This is because for downstream tasks such as topic modelling or sentiment analysis, there are a number of domain-specific words that need to be removed (very common verbs, useless abbreviations such as timezones, days of the week, etc.). Each word in each and every document needs to be compared against every word in the stopword list, which is an expensive operation over tens of thousands of documents.&lt;/p&gt;
&lt;p&gt;It's well known that sets have $O(1)$ (i.e. constant) lookup time as opposed to lists, which have $O(n)$ lookup time. In the &lt;code&gt;lemmatize()&lt;/code&gt; method, since we're checking each word for membership in the set of stopwords, we would expect sets to be much better than lists. To test this, we can rerun workflow #1 but this time, use a stopword &lt;em&gt;list&lt;/em&gt; instead.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stopwords&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stopwords&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%%time&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;preproc_stopword_list&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;clean&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lemmatize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_preproc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;preproc_stopword_list&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;CPU times: user 1min 17s, sys: 108 ms, total: 1min 18s
Wall time: 1min 18s
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;date&lt;/th&gt;
      &lt;th&gt;content&lt;/th&gt;
      &lt;th&gt;preproc_stopword_list&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;Stellar pitching kept the Mets afloat in the f...&lt;/td&gt;
      &lt;td&gt;[stellar, pitch, keep, mets, afloat, half, sea...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;Mayor Bill de Blasio‚Äôs counsel and chief legal...&lt;/td&gt;
      &lt;td&gt;[mayor, bill, blasio, counsel, chief, legal, a...&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;2016-06-30&lt;/td&gt;
      &lt;td&gt;In the early morning hours of Labor Day last y...&lt;/td&gt;
      &lt;td&gt;[early, labor, group, gunman, street, gang, cr...&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;This method now takes ~&lt;strong&gt;50% longer&lt;/strong&gt; than it did before (when using a stopword set), which is a &lt;strong&gt;1.5x&lt;/strong&gt; increase in run time! This makes sense because in this case, the stopword list is about 500 words long, and &lt;em&gt;each and every word&lt;/em&gt; in the corpus needs to be checked for membership in this reasonable-sized list.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Conclusions&quot;&gt;Conclusions&lt;a class=&quot;anchor-link&quot; href=&quot;#Conclusions&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In this exercise, a news article dataset (NY Times) was processed using a spaCy pipeline to output a list of lemmas representing the useful tokens present in each article's content. Because real-world news datasets are almost certainly bigger than this one, and can be unbounded in size, a fast, efficient NLP pipeline is necessary to perform any meaningful analysis on the data. The following steps are very useful in speeding up the spaCy pipeline.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disable unnecessary components in spaCy model:&lt;/strong&gt; The standard spaCy model's pipeline contains the tagger (to assign part-of-speech tags), the parser (to generate a dependency parse) and named entity recognition components. If any or none of these actions are desired, these components &lt;em&gt;must&lt;/em&gt; be disabled immediately after loading the model (as shown above).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use sets over lists for lookups:&lt;/strong&gt; When performing lookups to compare one set of tokens against another, always perform membership checks using sets - lists are significantly slower for lookups! The larger the list/set of stopwords, the bigger the performance gain seen when using sets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use custom language pipes when possible:&lt;/strong&gt; Setting up a language pipe using &lt;code&gt;nlp.pipe&lt;/code&gt; is an extremely flexible and efficient way to process large blocks of text. Even better, spaCy allows you to individually disable components for each specific sub-task, for example, when you need to separately perform part-of-speech tagging and named entity recognition (NER). &lt;a href=&quot;https://spacy.io/usage/processing-pipelines#disabling&quot;&gt;See the spaCy docs&lt;/a&gt; for examples on how to disable pipeline components during model loading, processing or handling custom blocks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use multiple cores when possible:&lt;/strong&gt; When processing individual documents completely independent of one another, consider parallelizing the workflow by passing the computation to multiple cores. As the number of documents becoms higher and higher, the performance gains can be tremendous. One just needs to ensure that the documents are divided up into chunks, all of which must fit into memory at any given time.&lt;/p&gt;
&lt;p&gt;I hope this was useful -- have fun testing these out in your next NLP project!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name>Prashanth Rao</name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://prrao87.github.io/blog/images/rocket.jpg" /><media:content medium="image" url="https://prrao87.github.io/blog/images/rocket.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>